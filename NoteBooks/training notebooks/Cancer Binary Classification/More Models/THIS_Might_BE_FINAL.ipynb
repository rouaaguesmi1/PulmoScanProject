{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8274443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Loading Data and Selecting EVEN Number of Scans Per Class (up to 50 each) ---\n",
      "Available Cancerous scans with labels: 27\n",
      "Available Non-Cancerous scans with labels: 71\n",
      "Selecting 27 scans from each class for balancing.\n",
      "Selected 27 Cancerous scans.\n",
      "Selected 27 Non-Cancerous scans.\n",
      "Total scans selected for preprocessing: 54\n",
      "\n",
      "Starting preprocessing for 54 selected scans (if not already done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing 54 Scans: 100%|██████████| 54/54 [02:40<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing finished/checked in 160.46 seconds.\n",
      "Final patient count for training/validation: 54\n",
      "  Balanced - Cancerous: 27, Non-Cancerous: 27\n",
      "CNNViTHybrid3DWithAttention(\n",
      "  (cnn_backbone): Sequential(\n",
      "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): SEBlock3D(\n",
      "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=1, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=1, out_features=16, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (4): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (6): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): SEBlock3D(\n",
      "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=2, out_features=32, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (9): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (11): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): SEBlock3D(\n",
      "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (14): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (patch_embed_conv): Conv3d(64, 128, kernel_size=(3, 4, 4), stride=(3, 4, 4))\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp_head): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Hybrid Model with Attention output shape: torch.Size([4, 1])\n",
      "Calculated positive weight for BCEWithLogitsLoss (balanced data): 0.9545\n",
      "\n",
      "Starting Training Hybrid Model with Attention (Balanced Data) for 50 epochs...\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary: Duration: 4.85s\n",
      "  Train Loss: 0.7197, Train Acc: 0.3721\n",
      "  Val Loss: 0.6857, Val Acc: 0.4545\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Summary: Duration: 3.34s\n",
      "  Train Loss: 0.6707, Train Acc: 0.4884\n",
      "  Val Loss: 0.6735, Val Acc: 0.5455\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Summary: Duration: 3.44s\n",
      "  Train Loss: 0.6815, Train Acc: 0.5116\n",
      "  Val Loss: 0.6803, Val Acc: 0.4545\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Summary: Duration: 3.71s\n",
      "  Train Loss: 0.6717, Train Acc: 0.5814\n",
      "  Val Loss: 0.6814, Val Acc: 0.4545\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Summary: Duration: 3.39s\n",
      "  Train Loss: 0.6925, Train Acc: 0.4651\n",
      "  Val Loss: 0.6692, Val Acc: 0.5455\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Summary: Duration: 3.28s\n",
      "  Train Loss: 0.6776, Train Acc: 0.4884\n",
      "  Val Loss: 0.6786, Val Acc: 0.5455\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Summary: Duration: 3.11s\n",
      "  Train Loss: 0.7018, Train Acc: 0.4651\n",
      "  Val Loss: 0.6971, Val Acc: 0.4545\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Summary: Duration: 3.17s\n",
      "  Train Loss: 0.6814, Train Acc: 0.4651\n",
      "  Val Loss: 0.6726, Val Acc: 0.5455\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Summary: Duration: 3.06s\n",
      "  Train Loss: 0.6773, Train Acc: 0.4651\n",
      "  Val Loss: 0.6677, Val Acc: 0.5455\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Summary: Duration: 3.09s\n",
      "  Train Loss: 0.6688, Train Acc: 0.6047\n",
      "  Val Loss: 0.6702, Val Acc: 0.5455\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Summary: Duration: 3.09s\n",
      "  Train Loss: 0.6755, Train Acc: 0.4651\n",
      "  Val Loss: 0.6842, Val Acc: 0.4545\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.6721, Train Acc: 0.4884\n",
      "  Val Loss: 0.6681, Val Acc: 0.3636\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Summary: Duration: 3.11s\n",
      "  Train Loss: 0.6862, Train Acc: 0.4186\n",
      "  Val Loss: 0.6615, Val Acc: 0.5455\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.6799, Train Acc: 0.4884\n",
      "  Val Loss: 0.6683, Val Acc: 0.6364\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Summary: Duration: 3.08s\n",
      "  Train Loss: 0.6623, Train Acc: 0.6744\n",
      "  Val Loss: 0.6584, Val Acc: 0.5455\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Summary: Duration: 3.05s\n",
      "  Train Loss: 0.6560, Train Acc: 0.5581\n",
      "  Val Loss: 0.6580, Val Acc: 0.6364\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Summary: Duration: 3.05s\n",
      "  Train Loss: 0.6420, Train Acc: 0.5814\n",
      "  Val Loss: 0.6759, Val Acc: 0.5455\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.7051, Train Acc: 0.4651\n",
      "  Val Loss: 0.6494, Val Acc: 0.4545\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Summary: Duration: 3.02s\n",
      "  Train Loss: 0.6860, Train Acc: 0.5116\n",
      "  Val Loss: 0.6545, Val Acc: 0.5455\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Summary: Duration: 3.06s\n",
      "  Train Loss: 0.6359, Train Acc: 0.6047\n",
      "  Val Loss: 0.6792, Val Acc: 0.6364\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Summary: Duration: 3.11s\n",
      "  Train Loss: 0.6753, Train Acc: 0.5581\n",
      "  Val Loss: 0.6554, Val Acc: 0.5455\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Summary: Duration: 3.03s\n",
      "  Train Loss: 0.6113, Train Acc: 0.6744\n",
      "  Val Loss: 0.6468, Val Acc: 0.5455\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Summary: Duration: 3.05s\n",
      "  Train Loss: 0.6094, Train Acc: 0.6977\n",
      "  Val Loss: 0.6626, Val Acc: 0.6364\n",
      "\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Summary: Duration: 3.07s\n",
      "  Train Loss: 0.5837, Train Acc: 0.6977\n",
      "  Val Loss: 0.6308, Val Acc: 0.4545\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Summary: Duration: 3.04s\n",
      "  Train Loss: 0.5361, Train Acc: 0.7674\n",
      "  Val Loss: 0.6514, Val Acc: 0.3636\n",
      "\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Summary: Duration: 3.01s\n",
      "  Train Loss: 0.5168, Train Acc: 0.7442\n",
      "  Val Loss: 0.6808, Val Acc: 0.5455\n",
      "\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Summary: Duration: 3.01s\n",
      "  Train Loss: 0.5567, Train Acc: 0.6744\n",
      "  Val Loss: 0.6927, Val Acc: 0.6364\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.6403, Train Acc: 0.4884\n",
      "  Val Loss: 0.6726, Val Acc: 0.5455\n",
      "\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.5109, Train Acc: 0.8140\n",
      "  Val Loss: 0.6047, Val Acc: 0.3636\n",
      "  Best model saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n",
      "\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Summary: Duration: 3.04s\n",
      "  Train Loss: 0.4943, Train Acc: 0.7209\n",
      "  Val Loss: 0.7598, Val Acc: 0.5455\n",
      "\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Summary: Duration: 3.03s\n",
      "  Train Loss: 0.6458, Train Acc: 0.5581\n",
      "  Val Loss: 0.6601, Val Acc: 0.6364\n",
      "\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Summary: Duration: 3.02s\n",
      "  Train Loss: 0.6184, Train Acc: 0.6279\n",
      "  Val Loss: 0.6293, Val Acc: 0.5455\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Summary: Duration: 3.02s\n",
      "  Train Loss: 0.5638, Train Acc: 0.8140\n",
      "  Val Loss: 0.6234, Val Acc: 0.6364\n",
      "\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Summary: Duration: 3.02s\n",
      "  Train Loss: 0.5034, Train Acc: 0.7907\n",
      "  Val Loss: 0.7074, Val Acc: 0.6364\n",
      "\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Summary: Duration: 3.00s\n",
      "  Train Loss: 0.4937, Train Acc: 0.7442\n",
      "  Val Loss: 0.8820, Val Acc: 0.6364\n",
      "\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.6105, Train Acc: 0.6744\n",
      "  Val Loss: 0.6999, Val Acc: 0.6364\n",
      "\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.4243, Train Acc: 0.8140\n",
      "  Val Loss: 0.6557, Val Acc: 0.5455\n",
      "\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Summary: Duration: 3.02s\n",
      "  Train Loss: 0.2669, Train Acc: 0.9302\n",
      "  Val Loss: 0.9339, Val Acc: 0.5455\n",
      "\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Summary: Duration: 3.02s\n",
      "  Train Loss: 0.6571, Train Acc: 0.6279\n",
      "  Val Loss: 0.6177, Val Acc: 0.5455\n",
      "\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Summary: Duration: 3.07s\n",
      "  Train Loss: 0.5594, Train Acc: 0.6047\n",
      "  Val Loss: 0.6294, Val Acc: 0.6364\n",
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Summary: Duration: 3.04s\n",
      "  Train Loss: 0.5607, Train Acc: 0.7442\n",
      "  Val Loss: 0.6209, Val Acc: 0.5455\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Summary: Duration: 3.04s\n",
      "  Train Loss: 0.4441, Train Acc: 0.9535\n",
      "  Val Loss: 0.6437, Val Acc: 0.6364\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Summary: Duration: 3.01s\n",
      "  Train Loss: 0.3852, Train Acc: 0.8837\n",
      "  Val Loss: 0.6637, Val Acc: 0.4545\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Summary: Duration: 3.01s\n",
      "  Train Loss: 0.4673, Train Acc: 0.8140\n",
      "  Val Loss: 0.9850, Val Acc: 0.5455\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Summary: Duration: 3.09s\n",
      "  Train Loss: 0.3827, Train Acc: 0.8372\n",
      "  Val Loss: 0.6749, Val Acc: 0.6364\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Summary: Duration: 3.04s\n",
      "  Train Loss: 0.2759, Train Acc: 0.9070\n",
      "  Val Loss: 0.8708, Val Acc: 0.6364\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Summary: Duration: 3.01s\n",
      "  Train Loss: 0.1442, Train Acc: 0.9535\n",
      "  Val Loss: 0.9264, Val Acc: 0.6364\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Summary: Duration: 3.03s\n",
      "  Train Loss: 0.9447, Train Acc: 0.5814\n",
      "  Val Loss: 0.6720, Val Acc: 0.6364\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Summary: Duration: 3.10s\n",
      "  Train Loss: 0.6434, Train Acc: 0.5814\n",
      "  Val Loss: 0.6384, Val Acc: 0.6364\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Summary: Duration: 3.04s\n",
      "  Train Loss: 0.4929, Train Acc: 0.8605\n",
      "  Val Loss: 0.6260, Val Acc: 0.6364\n",
      "\n",
      "Hybrid Model with Attention (Balanced Data) Training Finished.\n",
      "Training curves plot saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\training_curves_hybrid_attention_balanced.png\n",
      "\n",
      "Evaluating Hybrid Model with Attention (Balanced Data) on Validation Set...\n",
      "Loaded best hybrid attention model from C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\patient_level_hybrid_attention_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Validation Loss (Hybrid+Attention, Balanced): 0.6047\n",
      "\n",
      "--- Final Validation Metrics (Hybrid+Attention, Balanced) ---\n",
      "Accuracy:  0.3636\n",
      "Precision: 0.2500\n",
      "Recall:    0.2000\n",
      "F1-Score:  0.2222\n",
      "AUC-ROC:   0.5333\n",
      "\n",
      "Classification Report (Hybrid+Attention, Balanced):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Non-Cancer (0)       0.43      0.50      0.46         6\n",
      "    Cancer (1)       0.25      0.20      0.22         5\n",
      "\n",
      "      accuracy                           0.36        11\n",
      "     macro avg       0.34      0.35      0.34        11\n",
      "  weighted avg       0.35      0.36      0.35        11\n",
      "\n",
      "\n",
      "Confusion Matrix (Hybrid+Attention, Balanced):\n",
      "Confusion matrix plot saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\confusion_matrix_hybrid_attention_balanced.png\n",
      "ROC curve plot saved to C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\\roc_curve_hybrid_attention_balanced.png\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import scipy.ndimage\n",
    "from skimage.measure import label as skimage_label, regionprops\n",
    "from skimage.morphology import disk, binary_closing\n",
    "from skimage.segmentation import clear_border\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, auc, f1_score,\n",
    "                             precision_score, recall_score, accuracy_score, ConfusionMatrixDisplay)\n",
    "\n",
    "# Configuration\n",
    "# --- MODIFY THESE PATHS ---\n",
    "DSB_PATH = r\"C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Stages\"\n",
    "DSB_LABELS_CSV = r\"C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\stage1_labels.csv\"\n",
    "# --- MODIFIED: New output path for this balanced & attention model ---\n",
    "PREPROCESSED_DSB_PATH = r\"C:\\Users\\rouaa\\Documents\\Final_Pneumatect\\Preprocessed_Data_DSB_Balanced_Attention\"\n",
    "# ---\n",
    "\n",
    "# Preprocessing & Model Params\n",
    "TARGET_SPACING = [1.5, 1.5, 1.5]\n",
    "FINAL_SCAN_SIZE = (96, 128, 128) # (Depth, Height, Width)\n",
    "CLIP_BOUND_HU = [-1000.0, 400.0]\n",
    "PIXEL_MEAN = 0.25\n",
    "\n",
    "# Training Params\n",
    "NUM_CLASSES = 1\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 50 # Using 50 epochs as per recent request for new model variants\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "SCAN_LIMIT_PER_CLASS = 50 # Max scans per class if available\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(PREPROCESSED_DSB_PATH, exist_ok=True)\n",
    "\n",
    "# Random seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Data Loading and Selection (MODIFIED FOR BALANCING) ---\n",
    "\n",
    "print(f\"--- Loading Data and Selecting EVEN Number of Scans Per Class (up to {SCAN_LIMIT_PER_CLASS} each) ---\")\n",
    "\n",
    "if not os.path.isdir(DSB_PATH): raise SystemExit(f\"ERROR: DSB Scans path not found: {DSB_PATH}\")\n",
    "if not os.path.isfile(DSB_LABELS_CSV): raise SystemExit(f\"ERROR: DSB Labels CSV not found: {DSB_LABELS_CSV}\")\n",
    "dsb_labels_df = pd.read_csv(DSB_LABELS_CSV)\n",
    "dsb_labels_df = dsb_labels_df.rename(columns={'id': 'patient_id'})\n",
    "patient_labels_all = dsb_labels_df.set_index('patient_id')['cancer'].to_dict()\n",
    "scan_folders = [f for f in os.listdir(DSB_PATH) if os.path.isdir(os.path.join(DSB_PATH, f))]\n",
    "found_scan_ids = set(scan_folders)\n",
    "labeled_patient_ids_all = set(dsb_labels_df['patient_id'])\n",
    "common_ids_all = labeled_patient_ids_all.intersection(found_scan_ids)\n",
    "\n",
    "common_ids_cancer_available = [pid for pid in common_ids_all if patient_labels_all.get(pid) == 1]\n",
    "common_ids_non_cancer_available = [pid for pid in common_ids_all if patient_labels_all.get(pid) == 0]\n",
    "\n",
    "random.shuffle(common_ids_cancer_available)\n",
    "random.shuffle(common_ids_non_cancer_available)\n",
    "\n",
    "# Determine the number of scans to pick per class for balancing\n",
    "num_to_select_per_class = min(len(common_ids_cancer_available),\n",
    "                              len(common_ids_non_cancer_available),\n",
    "                              SCAN_LIMIT_PER_CLASS)\n",
    "\n",
    "print(f\"Available Cancerous scans with labels: {len(common_ids_cancer_available)}\")\n",
    "print(f\"Available Non-Cancerous scans with labels: {len(common_ids_non_cancer_available)}\")\n",
    "print(f\"Selecting {num_to_select_per_class} scans from each class for balancing.\")\n",
    "\n",
    "selected_cancer_ids = common_ids_cancer_available[:num_to_select_per_class]\n",
    "selected_non_cancer_ids = common_ids_non_cancer_available[:num_to_select_per_class]\n",
    "\n",
    "print(f\"Selected {len(selected_cancer_ids)} Cancerous scans.\")\n",
    "print(f\"Selected {len(selected_non_cancer_ids)} Non-Cancerous scans.\")\n",
    "\n",
    "scans_to_process = selected_cancer_ids + selected_non_cancer_ids\n",
    "random.shuffle(scans_to_process) # Shuffle combined list\n",
    "\n",
    "print(f\"Total scans selected for preprocessing: {len(scans_to_process)}\")\n",
    "patient_labels = {pid: patient_labels_all[pid] for pid in scans_to_process}\n",
    "\n",
    "\n",
    "# --- Preprocessing Functions (Identical to previous script) ---\n",
    "def load_scan_series(dicom_folder_path):\n",
    "    try:\n",
    "        series_ids = sitk.ImageSeriesReader.GetGDCMSeriesIDs(dicom_folder_path)\n",
    "        if not series_ids: return None, None, None\n",
    "        series_file_names = sitk.ImageSeriesReader.GetGDCMSeriesFileNames(dicom_folder_path, series_ids[0])\n",
    "        series_reader = sitk.ImageSeriesReader(); series_reader.SetFileNames(series_file_names)\n",
    "        itkimage = series_reader.Execute()\n",
    "        image_array = sitk.GetArrayFromImage(itkimage); origin = np.array(list(reversed(itkimage.GetOrigin()))); spacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "        return image_array, origin, spacing\n",
    "    except Exception as e: print(f\"Error reading DICOM {os.path.basename(dicom_folder_path)}: {e}\"); return None, None, None\n",
    "\n",
    "def resample(image, original_spacing, new_spacing=TARGET_SPACING):\n",
    "    try:\n",
    "        resize_factor = np.array(original_spacing) / np.array(new_spacing)\n",
    "        new_real_shape = image.shape * resize_factor; new_shape = np.round(new_real_shape)\n",
    "        real_resize_factor = new_shape / image.shape; actual_new_spacing = original_spacing / real_resize_factor\n",
    "        resampled_image = scipy.ndimage.zoom(image, real_resize_factor, mode='nearest', order=1)\n",
    "        return resampled_image, actual_new_spacing\n",
    "    except Exception as e: print(f\"Error resamping: {e}\"); return None, None\n",
    "\n",
    "def get_segmented_lungs(im_slice, hu_threshold=-320):\n",
    "    if im_slice.ndim != 2: return im_slice # Should be a 2D slice\n",
    "    binary = im_slice < hu_threshold\n",
    "    cleared = clear_border(binary)\n",
    "    label_image = skimage_label(cleared)\n",
    "    areas = [r.area for r in regionprops(label_image)]\n",
    "    areas.sort()\n",
    "    area_threshold = areas[-2] if len(areas) >= 2 else (areas[-1] if len(areas) == 1 else 0)\n",
    "    if area_threshold > 0:\n",
    "        for region in regionprops(label_image):\n",
    "            if region.area < area_threshold:\n",
    "                for coordinates in region.coords:\n",
    "                    label_image[coordinates[0], coordinates[1]] = 0\n",
    "    binary = label_image > 0\n",
    "    selem = disk(2)\n",
    "    binary = binary_closing(binary, selem)\n",
    "    selem_dilate = disk(5)\n",
    "    final_mask = ndi.binary_dilation(binary, structure=selem_dilate)\n",
    "    background_val = CLIP_BOUND_HU[0] - 1\n",
    "    segmented_slice = im_slice.copy()\n",
    "    segmented_slice[final_mask == 0] = background_val\n",
    "    return segmented_slice\n",
    "\n",
    "def normalize_hu(image, clip_bounds=CLIP_BOUND_HU):\n",
    "    min_bound, max_bound = clip_bounds\n",
    "    image = np.clip(image, min_bound, max_bound)\n",
    "    image = (image - min_bound) / (max_bound - min_bound)\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "def zero_center(image, pixel_mean=PIXEL_MEAN):\n",
    "    image = image - pixel_mean\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "def resize_scan_to_target(image, target_shape=FINAL_SCAN_SIZE):\n",
    "    if image.shape == target_shape: return image\n",
    "    resize_factor = np.array(target_shape) / np.array(image.shape)\n",
    "    try:\n",
    "        resized_image = scipy.ndimage.zoom(image, resize_factor, order=1, mode='nearest')\n",
    "        if resized_image.shape != target_shape:\n",
    "            current_shape = resized_image.shape\n",
    "            diff = np.array(target_shape) - np.array(current_shape)\n",
    "            pad = np.maximum(diff, 0); crop = np.maximum(-diff, 0)\n",
    "            pad_width = tuple((p // 2, p - p // 2) for p in pad)\n",
    "            resized_image = np.pad(resized_image, pad_width, mode='edge')\n",
    "            crop_slice = tuple(slice(c // 2, s - (c - c // 2)) for c, s in zip(crop, resized_image.shape))\n",
    "            resized_image = resized_image[crop_slice]\n",
    "        if resized_image.shape != target_shape: print(f\"ERROR: Resize failed. Shape {resized_image.shape} vs Target {target_shape}\"); return None\n",
    "        return resized_image.astype(np.float32)\n",
    "    except Exception as e: print(f\"Error resizing to target: {e}\"); return None\n",
    "\n",
    "def preprocess_scan_dsb(patient_id, input_base_path, output_base_path, force_preprocess=False):\n",
    "    scan_folder_path = os.path.join(input_base_path, patient_id)\n",
    "    output_filename = os.path.join(output_base_path, f\"{patient_id}.npz\")\n",
    "    if os.path.exists(output_filename) and not force_preprocess: return True\n",
    "    image, origin, spacing = load_scan_series(scan_folder_path)\n",
    "    if image is None: return False\n",
    "    resampled_image, new_spacing = resample(image, spacing, TARGET_SPACING)\n",
    "    if resampled_image is None: del image; return False;\n",
    "    del image;\n",
    "    segmented_lungs = np.zeros_like(resampled_image, dtype=np.float32)\n",
    "    for i in range(resampled_image.shape[0]): segmented_lungs[i] = get_segmented_lungs(resampled_image[i])\n",
    "    del resampled_image;\n",
    "    normalized_image = normalize_hu(segmented_lungs, clip_bounds=CLIP_BOUND_HU); del segmented_lungs;\n",
    "    centered_image = zero_center(normalized_image, pixel_mean=PIXEL_MEAN); del normalized_image;\n",
    "    final_image = resize_scan_to_target(centered_image, target_shape=FINAL_SCAN_SIZE); del centered_image;\n",
    "    if final_image is None: return False\n",
    "    try:\n",
    "        np.savez_compressed(output_filename, image=final_image.astype(np.float32))\n",
    "        return True\n",
    "    except Exception as e: print(f\"Error saving {patient_id}: {e}\"); return False\n",
    "\n",
    "#--- Preprocessing Execution (Identical logic, uses new path) ---\n",
    "successful_processed_ids = []\n",
    "failed_processed_ids = []\n",
    "print(f\"\\nStarting preprocessing for {len(scans_to_process)} selected scans (if not already done)...\")\n",
    "start_time = time.time()\n",
    "for patient_id in tqdm(scans_to_process, desc=f\"Preprocessing {len(scans_to_process)} Scans\"):\n",
    "    success = preprocess_scan_dsb(patient_id, DSB_PATH, PREPROCESSED_DSB_PATH, force_preprocess=False)\n",
    "    if success: successful_processed_ids.append(patient_id)\n",
    "    else: failed_processed_ids.append(patient_id)\n",
    "end_time = time.time()\n",
    "print(f\"\\nPreprocessing finished/checked in {end_time - start_time:.2f} seconds.\")\n",
    "final_patient_list = successful_processed_ids\n",
    "if not final_patient_list: raise SystemExit(\"No scans processed successfully. Cannot continue.\")\n",
    "patient_labels = {pid: patient_labels[pid] for pid in final_patient_list} # Use updated labels\n",
    "print(f\"Final patient count for training/validation: {len(final_patient_list)}\")\n",
    "final_cancer_count = sum(1 for pid in final_patient_list if patient_labels[pid] == 1)\n",
    "final_non_cancer_count = len(final_patient_list) - final_cancer_count\n",
    "print(f\"  Balanced - Cancerous: {final_cancer_count}, Non-Cancerous: {final_non_cancer_count}\")\n",
    "\n",
    "\n",
    "# --- Dataset and DataLoader (Identical) ---\n",
    "class PatientLevelDataset(Dataset):\n",
    "    def __init__(self, patient_ids, labels_dict, preprocessed_path):\n",
    "        self.patient_ids = patient_ids; self.labels_dict = labels_dict; self.preprocessed_path = preprocessed_path\n",
    "    def __len__(self): return len(self.patient_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_ids[idx]; label = self.labels_dict[patient_id]\n",
    "        scan_path = os.path.join(self.preprocessed_path, f\"{patient_id}.npz\")\n",
    "        try:\n",
    "            with np.load(scan_path) as npz_data: image = npz_data['image']\n",
    "            image_tensor = torch.from_numpy(image).float().unsqueeze(0)\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "            return image_tensor, label_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR loading {patient_id}: {e}\"); dummy = torch.zeros((1, *FINAL_SCAN_SIZE), dtype=torch.float32)\n",
    "            return dummy, torch.tensor(-1, dtype=torch.float32)\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    final_patient_list, test_size=0.2, random_state=SEED,\n",
    "    stratify=[patient_labels[pid] for pid in final_patient_list] # Stratify on balanced labels\n",
    ")\n",
    "train_dataset = PatientLevelDataset(train_ids, patient_labels, PREPROCESSED_DSB_PATH)\n",
    "val_dataset = PatientLevelDataset(val_ids, patient_labels, PREPROCESSED_DSB_PATH)\n",
    "NUM_WORKERS = 0\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# --- Model Definition (CNN-ViT Hybrid WITH SE ATTENTION BLOCKS) ---\n",
    "\n",
    "class SEBlock3D(nn.Module):\n",
    "    \"\"\" Squeeze-and-Excitation Block for 3D Convolutions. \"\"\"\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock3D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class CNNViTHybrid3DWithAttention(nn.Module): # Renamed class\n",
    "    def __init__(self,\n",
    "                 input_shape_dhw=FINAL_SCAN_SIZE,\n",
    "                 in_channels_cnn=1,\n",
    "                 cnn_channels_setup=[16, 32, 64],\n",
    "                 cnn_kernel_size=3,\n",
    "                 cnn_pool_kernel_size=2,\n",
    "                 se_reduction=16, # Reduction factor for SE blocks\n",
    "                 patch_size_3d=(3, 4, 4),\n",
    "                 embed_dim_vit=128,\n",
    "                 num_transformer_layers_vit=3,\n",
    "                 num_heads_vit=4,\n",
    "                 mlp_ratio_vit=2.0,\n",
    "                 dropout_vit=0.1,\n",
    "                 num_classes=1):\n",
    "        super(CNNViTHybrid3DWithAttention, self).__init__()\n",
    "\n",
    "        self.input_shape_dhw = input_shape_dhw\n",
    "        self.patch_size_3d = patch_size_3d\n",
    "        self.embed_dim_vit = embed_dim_vit\n",
    "\n",
    "        # 1. CNN Backbone with SE Blocks\n",
    "        cnn_layers = []\n",
    "        current_channels = in_channels_cnn\n",
    "        current_d, current_h, current_w = input_shape_dhw\n",
    "\n",
    "        for i, out_ch in enumerate(cnn_channels_setup):\n",
    "            cnn_layers.extend([\n",
    "                nn.Conv3d(current_channels, out_ch, kernel_size=cnn_kernel_size, stride=1, padding=cnn_kernel_size // 2),\n",
    "                nn.BatchNorm3d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                SEBlock3D(out_ch, reduction=se_reduction), # <<< ADDED SE BLOCK\n",
    "                nn.MaxPool3d(kernel_size=cnn_pool_kernel_size, stride=cnn_pool_kernel_size)\n",
    "            ])\n",
    "            current_channels = out_ch\n",
    "            current_d //= cnn_pool_kernel_size\n",
    "            current_h //= cnn_pool_kernel_size\n",
    "            current_w //= cnn_pool_kernel_size\n",
    "        \n",
    "        self.cnn_backbone = nn.Sequential(*cnn_layers)\n",
    "        self.cnn_feature_map_size_dhw = (current_d, current_h, current_w)\n",
    "        cnn_out_channels_final = current_channels\n",
    "\n",
    "        # 2. Patch Embedding for ViT\n",
    "        self.patch_embed_conv = nn.Conv3d(\n",
    "            cnn_out_channels_final, embed_dim_vit,\n",
    "            kernel_size=patch_size_3d, stride=patch_size_3d\n",
    "        )\n",
    "        num_patches_d = self.cnn_feature_map_size_dhw[0] // patch_size_3d[0]\n",
    "        num_patches_h = self.cnn_feature_map_size_dhw[1] // patch_size_3d[1]\n",
    "        num_patches_w = self.cnn_feature_map_size_dhw[2] // patch_size_3d[2]\n",
    "        self.num_patches = num_patches_d * num_patches_h * num_patches_w\n",
    "\n",
    "        # 3. CLS Token and Positional Embedding\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim_vit))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, embed_dim_vit))\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=.02)\n",
    "\n",
    "        # 4. Transformer Encoder\n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim_vit, nhead=num_heads_vit,\n",
    "            dim_feedforward=int(embed_dim_vit * mlp_ratio_vit),\n",
    "            dropout=dropout_vit, batch_first=True, activation='gelu'\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            transformer_encoder_layer, num_layers=num_transformer_layers_vit\n",
    "        )\n",
    "\n",
    "        # 5. Classification Head\n",
    "        self.norm_layer = nn.LayerNorm(embed_dim_vit)\n",
    "        self.mlp_head = nn.Linear(embed_dim_vit, num_classes)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=.02)\n",
    "            if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0); nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv3d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_backbone(x)\n",
    "        x = self.patch_embed_conv(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        batch_size = x.shape[0]\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.transformer_encoder(x)\n",
    "        cls_token_output = self.norm_layer(x[:, 0])\n",
    "        logits = self.mlp_head(cls_token_output)\n",
    "        return logits\n",
    "\n",
    "# Instantiate the Hybrid Model with Attention\n",
    "patient_model_attention = CNNViTHybrid3DWithAttention( # Use new class\n",
    "    input_shape_dhw=FINAL_SCAN_SIZE,\n",
    "    num_classes=NUM_CLASSES,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(patient_model_attention) # Print the new model structure\n",
    "try:\n",
    "    dummy_input = torch.randn(BATCH_SIZE, 1, *FINAL_SCAN_SIZE).to(DEVICE)\n",
    "    output = patient_model_attention(dummy_input)\n",
    "    print(f\"\\nHybrid Model with Attention output shape: {output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during hybrid model with attention test: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Loss and Optimizer ---\n",
    "# With balanced data, pos_weight should ideally be 1.0 or very close.\n",
    "# Let's verify, though it should be 1.0 if data is perfectly balanced in train_ids\n",
    "train_labels_list = [patient_labels[pid] for pid in train_ids]\n",
    "count_0 = train_labels_list.count(0); count_1 = train_labels_list.count(1)\n",
    "if count_0 == count_1 and count_0 > 0: # Perfect balance\n",
    "    pos_weight_val = 1.0\n",
    "elif count_1 > 0 and count_0 > 0: # Slight imbalance possible due to train/val split of balanced set\n",
    "    pos_weight_val = count_0 / count_1\n",
    "else: # One class missing or empty\n",
    "    pos_weight_val = 1.0\n",
    "    print(\"Warning: Training set has only one class or is empty after split. Using default pos_weight=1.\")\n",
    "\n",
    "pos_weight_tensor = torch.tensor([pos_weight_val], device=DEVICE)\n",
    "print(f\"Calculated positive weight for BCEWithLogitsLoss (balanced data): {pos_weight_val:.4f}\")\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "optimizer = optim.AdamW(patient_model_attention.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "#--- Training and Validation Functions (Identical) ---\n",
    "def train_one_epoch_patient(model, dataloader, criterion, optimizer, device, scaler):\n",
    "    model.train(); running_loss = 0.0; total_samples = 0; correct_predictions = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False, ncols=100)\n",
    "    for inputs, labels in progress_bar:\n",
    "        valid_indices = labels != -1 \n",
    "        inputs = inputs[valid_indices].to(device)\n",
    "        labels = labels[valid_indices].unsqueeze(1).to(device)\n",
    "        if inputs.nelement() == 0: continue \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
    "            outputs = model(inputs); loss = criterion(outputs, labels)\n",
    "        if torch.isnan(loss): print(\"NaN loss detected!\"); continue\n",
    "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "        running_loss += loss.item() * inputs.size(0); total_samples += inputs.size(0)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        correct_predictions += (preds == labels.bool()).sum().item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    if total_samples == 0: return 0.0, 0.0\n",
    "    return running_loss / total_samples, correct_predictions / total_samples\n",
    "\n",
    "def validate_patient(model, dataloader, criterion, device):\n",
    "    model.eval(); running_loss = 0.0; total_samples = 0; all_preds_proba = []; all_labels = []\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Validating\", leave=False, ncols=100)\n",
    "        for inputs, labels in progress_bar:\n",
    "            valid_indices = labels != -1\n",
    "            inputs = inputs[valid_indices].to(device)\n",
    "            labels = labels[valid_indices].unsqueeze(1).to(device)\n",
    "            if inputs.nelement() == 0: continue\n",
    "            with torch.amp.autocast(device_type=device.type, dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
    "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0); total_samples += inputs.size(0)\n",
    "            all_preds_proba.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    if total_samples == 0: return 0.0, np.array([]), np.array([])\n",
    "    return running_loss / total_samples, np.array(all_labels).flatten(), np.array(all_preds_proba).flatten()\n",
    "\n",
    "#--- Training Loop ---\n",
    "print(f\"\\nStarting Training Hybrid Model with Attention (Balanced Data) for {EPOCHS} epochs...\")\n",
    "best_val_loss = float('inf')\n",
    "train_losses, val_losses, train_accs, val_accs_list = [], [], [], []\n",
    "MODEL_SAVE_PATH = os.path.join(PREPROCESSED_DSB_PATH, \"patient_level_hybrid_attention_best.pth\") # New save path\n",
    "\n",
    "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    start_epoch_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch_patient(patient_model_attention, train_loader, criterion, optimizer, DEVICE, scaler)\n",
    "    val_loss, val_labels_epoch, val_preds_proba_epoch = validate_patient(patient_model_attention, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    train_losses.append(train_loss); val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    end_epoch_time = time.time(); epoch_duration = end_epoch_time - start_epoch_time\n",
    "    val_acc_epoch = 0.0\n",
    "    if len(val_labels_epoch) > 0 and val_labels_epoch.size > 0 and val_preds_proba_epoch.size > 0:\n",
    "        val_acc_epoch = accuracy_score(val_labels_epoch, (val_preds_proba_epoch > 0.5).astype(int))\n",
    "    val_accs_list.append(val_acc_epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Summary: Duration: {epoch_duration:.2f}s\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc_epoch:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss and len(val_labels_epoch) > 0:\n",
    "        best_val_loss = val_loss\n",
    "        try:\n",
    "            torch.save(patient_model_attention.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"  Best model saved to {MODEL_SAVE_PATH}\")\n",
    "        except Exception as e: print(f\"Error saving model: {e}\")\n",
    "            \n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nHybrid Model with Attention (Balanced Data) Training Finished.\")\n",
    "\n",
    "# --- Plot Training History ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, EPOCHS + 1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.title('Loss Curve (Hybrid+Attention, Balanced)'); plt.legend(); plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, EPOCHS + 1), train_accs, label='Train Acc')\n",
    "plt.plot(range(1, EPOCHS + 1), val_accs_list, label='Val Acc')\n",
    "plt.xlabel('Epochs'); plt.ylabel('Accuracy'); plt.title('Accuracy Curve (Hybrid+Attention, Balanced)'); plt.legend(); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plot_save_path = os.path.join(PREPROCESSED_DSB_PATH, \"training_curves_hybrid_attention_balanced.png\")\n",
    "plt.savefig(plot_save_path); print(f\"Training curves plot saved to {plot_save_path}\"); plt.close()\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "print(\"\\nEvaluating Hybrid Model with Attention (Balanced Data) on Validation Set...\")\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    try:\n",
    "        eval_model = CNNViTHybrid3DWithAttention(input_shape_dhw=FINAL_SCAN_SIZE, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "        eval_model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
    "        print(f\"Loaded best hybrid attention model from {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load best model: {e}. Using last epoch model.\"); eval_model = patient_model_attention\n",
    "else:\n",
    "    print(\"Best model file not found. Using last epoch model.\"); eval_model = patient_model_attention\n",
    "\n",
    "val_loss_final, final_val_labels, final_val_preds_proba = validate_patient(eval_model, val_loader, criterion, DEVICE)\n",
    "\n",
    "if len(final_val_labels) == 0: print(\"No valid validation predictions. Cannot evaluate.\")\n",
    "else:\n",
    "    print(f\"\\nFinal Validation Loss (Hybrid+Attention, Balanced): {val_loss_final:.4f}\")\n",
    "    final_val_preds_binary = (final_val_preds_proba > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(final_val_labels, final_val_preds_binary)\n",
    "    precision = precision_score(final_val_labels, final_val_preds_binary, zero_division=0)\n",
    "    recall = recall_score(final_val_labels, final_val_preds_binary, zero_division=0)\n",
    "    f1 = f1_score(final_val_labels, final_val_preds_binary, zero_division=0)\n",
    "    auc_roc = float('nan')\n",
    "    if len(np.unique(final_val_labels)) > 1: # Ensure more than one class in true labels\n",
    "        try: auc_roc = roc_auc_score(final_val_labels, final_val_preds_proba)\n",
    "        except ValueError as e: print(f\"AUC-ROC Error: {e}. Setting to NaN.\")\n",
    "    else: print(\"AUC-ROC cannot be calculated: only one class in y_true for validation.\")\n",
    "\n",
    "    print(\"\\n--- Final Validation Metrics (Hybrid+Attention, Balanced) ---\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\\nAUC-ROC:   {auc_roc:.4f}\")\n",
    "    target_names = ['Non-Cancer (0)', 'Cancer (1)']\n",
    "    print(\"\\nClassification Report (Hybrid+Attention, Balanced):\")\n",
    "    if len(np.unique(final_val_labels)) > 1:\n",
    "        print(classification_report(final_val_labels, final_val_preds_binary, target_names=target_names, zero_division=0))\n",
    "    else: print(\"Classification report not generated: only one class in y_true for validation.\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix (Hybrid+Attention, Balanced):\")\n",
    "    cm = confusion_matrix(final_val_labels, final_val_preds_binary, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=target_names)\n",
    "    disp.plot(cmap=plt.cm.Blues); plt.title(\"Confusion Matrix (Hybrid+Attention, Balanced)\")\n",
    "    cm_plot_save_path = os.path.join(PREPROCESSED_DSB_PATH, \"confusion_matrix_hybrid_attention_balanced.png\")\n",
    "    plt.savefig(cm_plot_save_path); print(f\"Confusion matrix plot saved to {cm_plot_save_path}\"); plt.close()\n",
    "\n",
    "    if not np.isnan(auc_roc):\n",
    "        fpr, tpr, _ = roc_curve(final_val_labels, final_val_preds_proba)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc_roc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve (Hybrid+Attention, Balanced)')\n",
    "        plt.legend(loc=\"lower right\"); plt.grid(True)\n",
    "        roc_plot_save_path = os.path.join(PREPROCESSED_DSB_PATH, \"roc_curve_hybrid_attention_balanced.png\")\n",
    "        plt.savefig(roc_plot_save_path); print(f\"ROC curve plot saved to {roc_plot_save_path}\"); plt.close()\n",
    "    else: print(\"ROC curve not plotted (AUC is NaN).\")\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
