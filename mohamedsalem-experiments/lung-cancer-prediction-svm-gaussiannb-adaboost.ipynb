{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4510352,"sourceType":"datasetVersion","datasetId":2636109}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## *Introduction*\n\nThis notebook develops a predictive model for lung cancer risk using a Kaggle dataset with 1000 patient records and 26 features, including demographics, lifestyle, and medical history. The target variable, Level (encoded as 0=Low, 1=Medium, 2=High), indicates cancer risk. We aim to classify risk levels using SVM, GaussianNB, and AdaBoost, with GridSearch for AdaBoost to optimize performance. The dataset is clean (no missing values or duplicates), and we evaluate models using accuracy, precision, recall, F1-score, and confusion matrices, followed by feature importance analysis to identify key predictors.\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## *Data Loading and Preprocessing*","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2025-04-27T19:22:17.192243Z","iopub.execute_input":"2025-04-27T19:22:17.192517Z","iopub.status.idle":"2025-04-27T19:22:21.429220Z","shell.execute_reply.started":"2025-04-27T19:22:17.192489Z","shell.execute_reply":"2025-04-27T19:22:21.428278Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/cancer-patients-and-air-pollution-a-new-link/cancer patient data sets.csv')","metadata":{"execution":{"iopub.status.busy":"2025-04-27T19:22:21.430963Z","iopub.execute_input":"2025-04-27T19:22:21.431541Z","iopub.status.idle":"2025-04-27T19:22:21.463384Z","shell.execute_reply.started":"2025-04-27T19:22:21.431506Z","shell.execute_reply":"2025-04-27T19:22:21.462337Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:48.036061Z","iopub.execute_input":"2025-04-27T15:15:48.036462Z","iopub.status.idle":"2025-04-27T15:15:48.058453Z","shell.execute_reply.started":"2025-04-27T15:15:48.036427Z","shell.execute_reply":"2025-04-27T15:15:48.057281Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:48.059854Z","iopub.execute_input":"2025-04-27T15:15:48.060196Z","iopub.status.idle":"2025-04-27T15:15:48.077490Z","shell.execute_reply.started":"2025-04-27T15:15:48.060165Z","shell.execute_reply":"2025-04-27T15:15:48.076301Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:48.081363Z","iopub.execute_input":"2025-04-27T15:15:48.081997Z","iopub.status.idle":"2025-04-27T15:15:48.181663Z","shell.execute_reply.started":"2025-04-27T15:15:48.081959Z","shell.execute_reply":"2025-04-27T15:15:48.179657Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:48.183397Z","iopub.execute_input":"2025-04-27T15:15:48.183739Z","iopub.status.idle":"2025-04-27T15:15:48.190339Z","shell.execute_reply.started":"2025-04-27T15:15:48.183709Z","shell.execute_reply":"2025-04-27T15:15:48.189307Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:48.191983Z","iopub.execute_input":"2025-04-27T15:15:48.192403Z","iopub.status.idle":"2025-04-27T15:15:48.206036Z","shell.execute_reply.started":"2025-04-27T15:15:48.192364Z","shell.execute_reply":"2025-04-27T15:15:48.204842Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.barplot(y='Level', x ='Smoking', data=df)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:48.207663Z","iopub.execute_input":"2025-04-27T15:15:48.208028Z","iopub.status.idle":"2025-04-27T15:15:48.530967Z","shell.execute_reply.started":"2025-04-27T15:15:48.207995Z","shell.execute_reply":"2025-04-27T15:15:48.529779Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select numeric columns (int64) before encoding\nnumeric_cols = df.select_dtypes(include=['int64']).columns\ncorr_matrix = df[numeric_cols].corr()\n\n# Visualize correlation matrix\nplt.figure(figsize=(12, 10))\nsns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\nplt.title('Correlation Matrix of Numeric Features')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:15:48.532402Z","iopub.execute_input":"2025-04-27T15:15:48.532752Z","iopub.status.idle":"2025-04-27T15:15:49.156646Z","shell.execute_reply.started":"2025-04-27T15:15:48.532721Z","shell.execute_reply":"2025-04-27T15:15:49.155287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder=LabelEncoder()\ndf['Level'] = encoder.fit_transform(df['Level'])","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:49.158402Z","iopub.execute_input":"2025-04-27T15:15:49.158974Z","iopub.status.idle":"2025-04-27T15:15:49.166986Z","shell.execute_reply.started":"2025-04-27T15:15:49.158831Z","shell.execute_reply":"2025-04-27T15:15:49.165719Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Level'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:15:49.168336Z","iopub.execute_input":"2025-04-27T15:15:49.168693Z","iopub.status.idle":"2025-04-27T15:15:49.184815Z","shell.execute_reply.started":"2025-04-27T15:15:49.168657Z","shell.execute_reply":"2025-04-27T15:15:49.183324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df=df.drop('Patient Id',axis=1)\ndf = df.drop(['Patient Id', 'index'], axis=1)\n# df = df.drop( 'index', axis=1)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:49.186706Z","iopub.execute_input":"2025-04-27T15:15:49.187060Z","iopub.status.idle":"2025-04-27T15:15:49.201179Z","shell.execute_reply.started":"2025-04-27T15:15:49.187030Z","shell.execute_reply":"2025-04-27T15:15:49.199605Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X=df.drop('Level',axis=1)\ny=df['Level']","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:49.202633Z","iopub.execute_input":"2025-04-27T15:15:49.203118Z","iopub.status.idle":"2025-04-27T15:15:49.215223Z","shell.execute_reply.started":"2025-04-27T15:15:49.203080Z","shell.execute_reply":"2025-04-27T15:15:49.214051Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Modeling* ","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T15:15:49.218419Z","iopub.execute_input":"2025-04-27T15:15:49.218784Z","iopub.status.idle":"2025-04-27T15:15:49.230473Z","shell.execute_reply.started":"2025-04-27T15:15:49.218754Z","shell.execute_reply":"2025-04-27T15:15:49.229327Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize models\nmodels = {\n    'SVM': SVC(),\n    'GaussianNB': GaussianNB(),\n    'AdaBoost': AdaBoostClassifier(random_state=42)\n}\n\n# Parameter grid for AdaBoost\nada_params = {\n    'n_estimators': [50, 100],\n    'learning_rate': [0.01, 0.1, 1.0]\n}\n\n# Train and evaluate each model\nresults = {}\nfor name, model in models.items():\n    print(f\"\\nTraining {name}...\")\n    if name == 'AdaBoost':\n        # Apply GridSearch for AdaBoost\n        grid = GridSearchCV(model, ada_params, cv=5, scoring='accuracy', n_jobs=-1)\n        grid.fit(X_train, y_train)\n        model = grid.best_estimator_\n        print(f\"Best AdaBoost Params:\", grid.best_params_)\n        print(f\"Best CV Accuracy:\", grid.best_score_)\n    else:\n        # Train directly for SVM and GaussianNB\n        model.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)  # Make predictions\n    accuracy = accuracy_score(y_test, y_pred)\n    results[name] = accuracy\n    print(f\"Test Accuracy for {name}: {accuracy:.4f}\")\n    print(f\"Classification Report for {name}:\\n{classification_report(y_test, y_pred)}\")\n    print(f\"Confusion Matrix for {name}:\\n{confusion_matrix(y_test, y_pred)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:15:49.231706Z","iopub.execute_input":"2025-04-27T15:15:49.232040Z","iopub.status.idle":"2025-04-27T15:15:53.553186Z","shell.execute_reply.started":"2025-04-27T15:15:49.232008Z","shell.execute_reply":"2025-04-27T15:15:53.551852Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Feature Importance (RandomForest)","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(random_state=42)\nrf.fit(X_train, y_train)\nimportance_df = pd.DataFrame({'Feature': X.columns, 'Importance': rf.feature_importances_})\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\nprint(\"\\nRandomForest Feature Importance:\")\nprint(importance_df)\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=importance_df.head(10))\nplt.title('Top 10 Feature Importance (RandomForest)')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:15:53.554839Z","iopub.execute_input":"2025-04-27T15:15:53.555201Z","iopub.status.idle":"2025-04-27T15:15:54.268779Z","shell.execute_reply.started":"2025-04-27T15:15:53.555165Z","shell.execute_reply":"2025-04-27T15:15:54.267484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot comparison\nplt.figure(figsize=(8, 6))\nsns.barplot(x=list(results.keys()), y=list(results.values()))\nplt.title('Model Comparison - Test Accuracy')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:15:54.270066Z","iopub.execute_input":"2025-04-27T15:15:54.270378Z","iopub.status.idle":"2025-04-27T15:15:54.488957Z","shell.execute_reply.started":"2025-04-27T15:15:54.270351Z","shell.execute_reply":"2025-04-27T15:15:54.487804Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Conclusion :*\n\nSVM achieved the highest test accuracy (97.33%), excelling in classifying all risk levels, followed by GaussianNB and AdaBoost (both 90.00%). AdaBoost, optimized with GridSearch (learning_rate=0.01, n_estimators=100), struggled with Low-risk recall. RandomForest feature importance identified Coughing of Blood (12.49%), Passive Smoker (10.33%), and Obesity (9.33%) as top predictors, highlighting their strong influence on lung cancer risk. High accuracies suggest a potentially oversimplified dataset, requiring external validation to ensure robustness.","metadata":{}}]}